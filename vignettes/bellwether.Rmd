---
title: "Bellwether Tutorial"
output: html_document
date: '2023-05-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# devtools::install_github("joshqsumner/pcvr")
library(pcvr)
library(ggplot2)
library(patchwork)
```


# Example Bellwether (Lemnatech) Workflow

Pending further development

```{r, echo=F, eval=F, include=F}
#* ***** `NOTES` ***** 
#* The files at public/Phenotyping/Center Equipment/Bellwether_tutorial/3_data_analysis_files/*.Rmd outline analysis for an individual phenotype each, in a veeery long format.
#* I would like to hit those main points for an example phenotype but with a few other additions. Below I am making an outline.
#* 
#* Read in Data (read.pcv vs read.pcv.bw, show differences and how to get to the same place with both?)
#*    Remove Outliers
#*    Adjust Time
#*    Check Watering
#* 
#* "Canonical Analysis": what always happens? Show FREM, maybe use pcv.box.
#* 
#* Single Value Trait phenotype analysis: Here I want to hit all of Katie's stuff, but more elegantly ideally.
#*    loess plots
#*    boxplot comparison of last day (both these might just be canonical? Might change canon to only be SV traits FREM)
#*    possibly an ordination? I don't like this but I think people do it a lot.
#*    At least a mention of the more robust modeling, probably just brms helpers then loading example data. 
#*      Possibly will want to show other options, nlme, nlqr?
#* 
#* Multi Value Trait phenotype analysis: Joyplots, EMD, networks, etc.
#*    Ideally this will be from SINC2 extra plants or some other group that has actual color differences
#* 
#* 
#* 
```

## Read In Data

### `read.pcv`

Bellwether data can be very large so this vignette will use a small bellwether dataset that is already subset to remove most multi-value traits (most color histograms). That data is available on [github](https://github.com/joshqsumner/pcvrTestData/blob/main/smallPhenotyperRun.csv).

The single value traits can be read in and converted to wide format with `read.pcv`, here using `data.table::fread` for speed.

```{r}
library(data.table)

sv<-read.pcv("https://media.githubusercontent.com/media/joshqsumner/pcvrTestData/main/smallPhenotyperRun.csv", mode="wide", singleValueOnly = T, reader="fread")

sv$genotype = substr(sv$barcode, 3,5)
sv$genotype = ifelse(sv$genotype == "002", "B73",
                     ifelse(sv$genotype == "003", "W605S",
                            ifelse(sv$genotype == "004", "MM", "Mo17")))
sv$fertilizer = substr(sv$barcode, 8, 8)
sv$fertilizer = ifelse(sv$fertilizer == "A", "100",
                     ifelse(sv$fertilizer == "B", "50", "0"))
```


Sometimes large plantCV output may be too large to be read into memory for R. In that case `read.pcv` has a `filter` argument which will filter rows using awk through linux/unix outside of R. That feature would work as shown below to read only single value traits into memory. This can take a few minutes but allows the entirely workflow to be documented in one R file. 


```{r, eval=F, echo=T}
example<-read.pcv("prohibitivelyLargeFile.csv",
   filters = list("trait in area, convex_hull_area, solidity, perimeter, width, height, longest_path, convex_hull_vertices, ellipse_major_axis, ellipse_minor_axis, ellipse_angle, ellipse_eccentricity, hue_circular_mean, hue_circular_std, hue_median", "sample in default"))
```

### `read.pcv.bw`

Bellwether data can also be read in with `read.pcv.bw` which is a wrapper around `read.pcv` which attempts to do several common tasks related bellwether data joining internally. This should be considered experimental as bellwether experiments can take many formats and this has only been considered with a few datasets.

```{r, eval=F}
bw<-read.pcv.bw( file="https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/bwTestPhenos.csv",metaCol=NULL, mode="long")

bw<-read.pcv.bw( file="https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/bwTestPhenos.csv",metaCol="meta", metaForm="vis_view_angle_zoom_horizontal_gain_exposure_v_new_n_rep", joinSnapshot = "id", mode="long")

bw<-read.pcv.bw( file="https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/bwTestPhenos.csv",
   snapshotFile="https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/bwTestSnapshot.csv",
   designFile="https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/bwTestDesign.csv",
   metaCol="meta",metaForm="vis_view_angle_zoom_horizontal_gain_exposure_v_new_n_rep",
   joinSnapshot="id",conversions = list(area=13.2*3.7/46856), mode="long" )
```


### Other metadata

Often we want to convert our timestamp data from the lemnatech into either days after start (DAS), days after planting (DAP), or days after emergence (DAE). By default the `bw.time` function will add columns called DAS, DAP, and DAE to your data. Days after emergence requires using a phenotype and a value to classify emergence. Here an area greater than 10 pixels is considered an emerged plant. In this example with a planting delay of 0 DAP and DAE will be the same, but both are still created for the purpose of the example.

```{r}
sv<-bw.time(sv, plantingDelay = 0, phenotype="area.pixels", cutoff=10, timeCol="timestamp", group=c("barcode", "rotation"), plot=T)
```

If we plot our time data then we might see that there are a few outliers or we might check a summary of our phenotype and see some outliers, either from experiment conditions or from the image analysis workflow. The `bw.outliers` function can be used to remove outliers relative to a phenotype using cook's distance. Here just over 6 percent of data are removed as outliers.

```{r}
sv<-bw.outliers(sv, phenotype="area.pixels", group = c("DAS", "genotype", "fertilizer"), plotgroup = c("barcode", "rotation"))
```

We might also want to check the watering data, which can be read easily from json with `bw.water`.

```{r}
water<-bw.water("https://raw.githubusercontent.com/joshqsumner/pcvrTestData/main/metadata.json")

water$genotype = substr(water$barcode, 3,5)
water$genotype = ifelse(water$genotype == "002", "B73",
                     ifelse(water$genotype == "003", "W605S",
                            ifelse(water$genotype == "004", "MM", "Mo17")))
water$fertilizer = substr(water$barcode, 8, 8)
water$fertilizer = ifelse(water$fertilizer == "A", "100",
                     ifelse(water$fertilizer == "B", "50", "0"))
ggplot(water[water$weight_after!=-1,], aes(x=DAS, y=water_amount, group=barcode,color=interaction(genotype,fertilizer)))+
  geom_line()+
  pcv_theme()+
  guides(color=guide_legend(title="Condition", nrow=3,byrow=T))+
  theme(legend.position="bottom")
```

Finally, we can combine images taken at different angles of the same plant on a given day with `aggregate`, where we will also remove some columns we aren't using.

```{r}
phenotypes <- c('area.pixels', 'convex_hull_area.pixels', 'convex_hull_vertices', 'ellipse_angle.degrees', 'ellipse_eccentricity', 'ellipse_major_axis.pixels', 'ellipse_minor_axis.pixels', 'height.pixels', 'hue_circular_mean.degrees', 'hue_circular_std.degrees', 'hue_median.degrees', 'longest_path.pixels', 'perimeter.pixels', 'solidity', 'width.pixels')
phenoForm<-paste0("cbind(", paste0(phenotypes, collapse=", "), ")")
groupForm<-"DAS+DAP+DAE+barcode+genotype+fertilizer"
form<-as.formula(paste0(phenoForm, "~", groupForm))
sv<-aggregate(form, data=sv, mean, na.rm=T)
```


## FREM

Now that our data is read in and has undergone some basic quality control we want to know which phenotypes are best explained by our design variables. The `frem` function partitions variance using a fully random effects model (frem). Here we provide our dataframe, the design variables, the phenotypes, and the column representing time. By default `frem` will use the last timepoint, but this is controlled with the `time` argument.

```{r}
frem(sv, des=c("genotype", "fertilizer"),
     phenotypes=c('area.pixels', 'convex_hull_area.pixels', 'convex_hull_vertices', 'ellipse_angle.degrees', 'ellipse_eccentricity', 'ellipse_major_axis.pixels', 'ellipse_minor_axis.pixels', 'height.pixels', 'hue_circular_mean.degrees', 'hue_circular_std.degrees', 'hue_median.degrees', 'longest_path.pixels', 'perimeter.pixels', 'solidity', 'width.pixels'),
     timeCol="DAS", cor=T, returnData=F, combine=F, markSingular=T)
```

Here we look at how much variance in each phenotype was explained over the course of the experiment.

```{r}
frem(sv, des=c("genotype", "fertilizer"),
     phenotypes=c('area.pixels', 'convex_hull_area.pixels', 'convex_hull_vertices', 'ellipse_angle.degrees', 'ellipse_eccentricity', 'ellipse_major_axis.pixels', 'ellipse_minor_axis.pixels', 'height.pixels', 'hue_circular_mean.degrees', 'hue_circular_std.degrees', 'hue_median.degrees', 'longest_path.pixels', 'perimeter.pixels', 'solidity', 'width.pixels'),
     timeCol="DAS", F, F, F, T, "all")
```

This informs our next steps. Hue and size based phenotypes are well explained by our design variables so we might decide to focus more complex analyses on those. In this experiment mini maize is one of the genotypes and the fertilizer treatment has an option with no nitrogen, so this intuitively makes sense and passes an eye check.

## Single Value Traits

Most analysis focus on single value traits, that is phenotypes where one image returns on numeric value such as area or height. These can be compared longitudinally or with respect to individual days. To make this analysis more intuitive we often want to convert our pixel phenotypes into more comprehensible units.

```{r}
pixels_per_cmsq <- 42.5^2   # pixel per cm^2
sv$area_cm2<-sv$area.pixels / pixels_per_cmsq
sv$height_cm <- sv$height.pixels/42.5
```


### Loess Plots

Trendlines help us decide what next steps make the most sense and give a general impression of which conditions yielded healthier plants.

```{r}
ggplot(sv, aes(x=DAS, y=area.pixels, group=interaction(genotype, fertilizer, lex.order=T),
                                color = interaction(genotype, fertilizer, lex.order=T)))+
  geom_smooth(method="loess", se=F)+
  labs(y=expression("Area"~"(cm"^2~")"),
       color="Soil and\nInoculation")+
  pcv_theme()+theme(axis.text.x.bottom=element_text(angle=0))
```


### Single day comparisons

```{r}
pcvBox(sv[sv$genotype=='MM' & sv$DAE==15, ], x="fertilizer", y="area_cm2", compare="0", showPoints = T)
```

### Longitudinal Modeling

Longitudinal modeling is the most comprehensive way to use the single value traits from a bellwether experiment. Longitudinal modeling can also be complicated compared to single timepoint analyses. Statistical complications including changes in variance, non-linearity, and autocorrelation present potential problems in analyses. To address these we recommend using heirarchical models. `pcvr` attempts to lower the barrier to entry for these models with helper functions for use with `brms`.

#### Growth Model Forms

Based on literature and observed trends there are 6 common growth models that `pcvr` supports. Those are shown here using the `growthSim` function.

```{r}
simdf<-growthSim("logistic", n=20, t=25, params = list("A"=c(200,160), "B"=c(13, 11), "C"=c(3, 3.5)))
l<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+
  geom_line(aes(color=group))+labs(title="Logistic")+theme_minimal()+theme(legend.position="none")

simdf<-growthSim("gompertz", n=20, t=25, params = list("A"=c(200,160), "B"=c(13, 11), "C"=c(0.2, 0.25)))
g<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+
  geom_line(aes(color=group))+labs(title="Gompertz")+theme_minimal()+theme(legend.position="none")

simdf<-growthSim("monomolecular", n=20, t=25, params = list("A"=c(200,160), "B"=c(0.08, 0.1)))
m<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+
  geom_line(aes(color=group))+labs(title="Monomolecular")+theme_minimal()+theme(legend.position="none")

simdf<-growthSim("exponential", n=20, t=25, params = list("A"=c(15, 20), "B"=c(0.095, 0.095)))
e<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+
  geom_line(aes(color=group))+labs(title="Exponential")+theme_minimal()+theme(legend.position="none")

simdf<-growthSim("linear", n=20, t=25, params = list("A"=c(1.1, 0.95)))
ln<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+
  geom_line(aes(color=group))+labs(title="Linear")+theme_minimal()+theme(legend.position="none")

simdf<-growthSim("power law", n=20, t=25, params = list("A"=c(16, 11), "B"=c(0.75, 0.7)))
pl<-ggplot(simdf,aes(time, y, group=interaction(group,id)))+ geom_line(aes(color=group))+
  labs(title="Power Law")+theme_minimal()+theme(legend.position="none")

(l+g+m)/(e+ln+pl)

```

Typically at least one of these models will be a good fit to your bellwether data, with gompertz models being the most broadly useful so far. In this experiment the plants were not germinated before being added to the machine, so we might not see asymptotic size. Still, conceptually we know that these plants will stop growing in the near future so we might use a gompertz model in place of the exponential model that looks most like our loess trendlines.


#### Model setup 

Coding a multilevel bayesian model can be involved. Even with the greatly simplified syntax used by `brms` this can present a barrier to entry for some people who could benefit from using very robust models. To help get around this potential issue for the specific case of measuring growth over time `pcvr` includes several functions to work with `brms`, the first of which is `growthSS`, a self-starter helper function for use with `brms::brm`.

##### submodel options

There are several ways to consider variance over time. By default almost all modeling assumes homoscedasticity, that is constant variance across predictor variables (time here). That assumption is very unrealistic in biological settings since all seeds/seedlings will start from a very low area but will grow differently through the experiment. The `growthSS` function has three options for modeling variance: homo, linear, spline. There are many ways that we could model variance, but these three are implemented for general use. Splines will almost always yield the best fit to your data.

![subModelComparisons.png](Different sub model options shown and compared with LOO Information Criterion)

##### Prior Distributions

An important part of bayesian statistics is setting an appropriate prior. These represent your knowledge about the field and are used along with your collected data to yield results. Priors should generally be weak relative to your data, meaning that if your prior belief is wrong then your experiment can move the posterior distribution away from the prior in a meaningful way.

In `growthSS` priors can be specified as a brmsprior object (in which case it is used as is), a named list (names representing parameters), or a numeric vector, where values will be used to generate lognormal priors with a long right tail. Lognormal priors with long right tails are used because the values for our growth curves are strictly positive and the lognormal distribution is easily interpreted. The tail is a product of the variance, which is assumed to be 0.25 for simplicity and to ensure priors are wide. This means that only a location parameter needs to be provided. If a list is used then each element of the list can be length 1 in which case each group will use the same prior or it can be a vector of the same length as `unique(data$group)` where `group` is your grouping variable from the form argument to `growthSS`. If a vector is used then a warning will be printed to check that the assumed order of groups is correct. The `growthSim` function can be useful in thinking about what a reasonable prior distribution might be, although priors should not be picked by trying to get a great fit by eye to your collected data.

We can check our priors with the `plotPrior` function.

```{r}
priors = list("A" = 130, "B" = 10, "C" = 1.2)
priorPlots<-plotPrior(priors)
priorPlots[[1]]/priorPlots[[2]]/priorPlots[[3]]
```


##### Using `growthSS`

Now we're ready to define the necessary variables in our data and use the `growthSS` function. 

```{r}
sv$group<-interaction(sv$fertilizer, sv$genotype)

ss<-growthSS(model="gompertz", form =  area_cm2~DAS|barcode/group, sigma="spline", df=sv,
             priors = list("A" = 130, "B" = 10, "C" = 1.2))
```

#### Running Models

The `brms` package is not automatically imported by `pcvr`, so before fitting models we need to load that package.

```{r}
library(brms)
```

Now we can fit our model using our `growthSS` outputs.

```{r, eval=F}
fit <- brm(ss$formula, prior = ss$prior, data = ss$df, family = ss$family, 
                           iter = 2000, cores = 4, chains = 4, init = ss$initfun, 
                           control = list(adapt_delta = 0.999, max_treedepth = 20), backend = "cmdstanr")
save(fit, file="bellwether_fit.rdata")
```

#### Check Model Fit

We can visualize credible intervals from a `brms` model and compare that to our growth trendlines to get an intuitive understanding of how well the model fit.

```{r}
brmPlot(fit, form = area_cm2~DAS|barcode/group, df = ss$df)
```

#### Test Hypotheses

Now we probably have some ideas about what we want to test in our data. The `brms::hypothesis` function offers incredible flexibility to test all kinds of hypotheses. For some comparisons `pcvr` has a helper function called `brmViolin` to visualize posterior distributions and the posterior probability of some hypotheses associated with them.

```{r}
brmViolin(model = list(s0_gompertz_area), params = NULL, cores = 10,
              hyp="num/denom>1.05", compareX = c("0.drip", "0.mock", "0.slurry"), againstY = "0.mock", group_sep = "[.]",
              groups_into = c("soil", "inoc"), x="inoc", facet="soil", returnData=F)

```

This result tells us that... XYZ


## Multi Value Traits

```{r}
hue_wide<-read.pcv("https://media.githubusercontent.com/media/joshqsumner/pcvrTestData/main/smallPhenotyperRun.csv", mode="wide", singleValueOnly = T, multiValPattern = "hist", reader="fread")

hue_long<-read.pcv("https://media.githubusercontent.com/media/joshqsumner/pcvrTestData/main/smallPhenotyperRun.csv", mode="long", singleValueOnly = F, reader="fread")
```


### Joyplots

### Ordination?

### Earth Mover's Distance

#### Network Analysis








